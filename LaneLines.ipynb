{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import glob\n",
    "import settings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Load data from pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pickle.load( open( \"camera_calibration.p\", \"rb\" ) )\n",
    "camera_matrix = data['mtx']\n",
    "dist_coeffs = data['dist']\n",
    "\n",
    "perspective_transform_data = pickle.load(open(\"perspective.p\", 'rb'))\n",
    "x_pixels_per_meter = perspective_transform_data['x_pixels_per_meter']\n",
    "y_pixels_per_meter = perspective_transform_data['y_pixels_per_meter']\n",
    "M = perspective_transform_data['homography_matrix']\n",
    "src_pts = perspective_transform_data['source_points']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Image example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is :  ./test_images/test1.jpg\n",
      "file is :  ./test_images/test5.jpg\n",
      "file is :  ./test_images/test6.jpg\n",
      "file is :  ./test_images/test2.jpg\n",
      "file is :  ./test_images/test4.jpg\n",
      "file is :  ./test_images/test3.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "test_images = []\n",
    "for file in glob.glob('./test_images/test*'):\n",
    "    print('file is : ', file)\n",
    "    test_images.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_images.append('./test_images/straight_lines1.jpg')\n",
    "test_images.append('./test_images/straight_lines2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_1 = mpimg.imread(test_images[3])\n",
    "plt.imshow(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# im = cv2.imread(test_images[0])\n",
    "# imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "# ret,thresh = cv2.threshold(imgray,127,255,0)\n",
    "# print('ret: ', ret)\n",
    "# print('thresh: ', thresh.\n",
    "#       shape)\n",
    "# im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "# print('im2: ', im2.shape)\n",
    "# print('contours: ', len(contours))\n",
    "# plt.imshow(im2)\n",
    "# cv2.drawContours(im, contours, -1, (0, 255, 0), 3)\n",
    "# # plt.imshow(im)\n",
    "# area = cv2.contourArea(contours[0])\n",
    "# print('area: ', area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Lane Line Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LaneLineFinder():\n",
    "    \"\"\"\n",
    "    This class performs the individual calculations on a single lane line\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size, x_pixels_per_meter, y_pixels_per_meter, kind = 'none'):\n",
    "        self.img_size = img_size\n",
    "        self.x_pixels_per_meter = x_pixels_per_meter\n",
    "        self.y_pixels_per_meter = y_pixels_per_meter\n",
    "        self.kind = kind # specify left or right lane\n",
    "        self.line_mask = np.ones((img_size[1], img_size[0]), dtype=np.uint8) # create 2D line mask\n",
    "        self.found = False\n",
    "        self.recent_centers = []\n",
    "        self.smooth_factor = 15\n",
    "        \n",
    "    def find_lane_line(self, mask, FLAG):\n",
    "        \"\"\"\n",
    "        Perform convolutional sliding window\n",
    "        Identify points of interest and save them\n",
    "        Then pass the saved points to fit_lane_line where you apply polynomial fit\n",
    "        input: mask (shape [500, 600])\n",
    "        \"\"\"\n",
    "        img_width = self.img_size[0] # 500\n",
    "        img_height = self.img_size[1] # 600\n",
    "\n",
    "#         self.window_width = 40\n",
    "#         self.window_height = 70\n",
    "        \n",
    "        self.window_width = 40\n",
    "        self.window_height = 70\n",
    "\n",
    "        window_centroids = self.find_window_centroids(mask, \n",
    "                                                 window_width = self.window_width, \n",
    "                                                 window_height = self.window_height,\n",
    "                                                 margin_width = 30,\n",
    "                                                 margin_height = 35,\n",
    "                                                 FLAG = FLAG)\n",
    "        \n",
    "        points, x_left_right = self.get_line_pts(mask, window_centroids)\n",
    "        \n",
    "        weighted, tmp, mask =  draw_lines_weighted(points, mask)\n",
    "        \n",
    "        # TODO: Finish fit_line instantiation\n",
    "        left_lane, right_lane = self.fit_lines(window_centroids, \n",
    "                                               x_left_right[0], \n",
    "                                               x_left_right[1], \n",
    "                                               self.window_width, \n",
    "                                               self.window_height)\n",
    "        \n",
    "        \n",
    "        road_lines = self.draw_lines(left_lane, right_lane)\n",
    "        # points now is an array containing [left_points, right_points]\n",
    "        return road_lines\n",
    "        \n",
    "    \n",
    "    def find_window_centroids(self, mask, \n",
    "                          window_width, \n",
    "                          window_height, \n",
    "                          margin_width,\n",
    "                          margin_height,\n",
    "                          FLAG):\n",
    "        img_width = self.img_size[0] # 500\n",
    "        img_height = self.img_size[1] # 600\n",
    "\n",
    "        window = np.ones((window_width))\n",
    "        n_vertical_slices = img_height // window_height # 8 iterations\n",
    "        window_centroids = []\n",
    "        \n",
    "        left_x_vals = []\n",
    "        right_x_vals = []\n",
    "        \n",
    "        # sum up the pixels within the bottom box\n",
    "        # go down 3/4 into height\n",
    "\n",
    "        v_step = img_height // window_height\n",
    "        window_vertical_start = int((3/4) * img_height)\n",
    "        window_horizontal_start = int(img_width/2)\n",
    "\n",
    "\n",
    "        l_sum = np.sum(mask[window_vertical_start:, :window_horizontal_start], axis = 0)\n",
    "        l_center = np.argmax(np.convolve(window, l_sum)) - window_width/2\n",
    "\n",
    "        r_sum = np.sum(mask[window_vertical_start:, window_horizontal_start:], axis = 0)\n",
    "        r_center = np.argmax(np.convolve(window, r_sum)) - window_width/2 + img_width/2\n",
    "\n",
    "        left_x_vals.append(l_center)\n",
    "        right_x_vals.append(r_center)\n",
    "        \n",
    "        \n",
    "#         window_centroids.append([l_center, r_center])\n",
    "        for level in range(1, n_vertical_slices):\n",
    "            # convolve window with vertical slice of image\n",
    "            # first sum up the image vertically\n",
    "            window_start_vertical = img_height - (level + 1) * (window_height)\n",
    "            window_end_vertical = img_height - (level * window_height)\n",
    "\n",
    "            image_layer = np.sum(mask[window_start_vertical : window_end_vertical,:], axis = 0)\n",
    "            conv_signal = np.convolve(window, image_layer)\n",
    "\n",
    "            # Use past centroid as a reference to find the best centroid within a margin\n",
    "            offset = int(window_width / 2)\n",
    "            l_min_index = int(max(l_center + offset - margin_width, 0))\n",
    "            l_max_index = int(min(l_center + offset + margin_width, img_width))\n",
    "            l_center = np.argmax(conv_signal[l_min_index: l_max_index]) + l_min_index - offset\n",
    "\n",
    "            # look near the first centroid for the right centroids\n",
    "            r_min_index = int(max(r_center + offset - margin_width, 0))\n",
    "            r_max_index = int(min(r_center + offset + margin_width, img_width))\n",
    "            r_center = np.argmax(conv_signal[r_min_index: r_max_index]) + r_min_index - offset\n",
    "            \n",
    "            left_x_vals.append(l_center)\n",
    "            right_x_vals.append(r_center)\n",
    "            \n",
    "        \n",
    "        left_centers = moving_average_scale(left_x_vals)\n",
    "        right_centers = moving_average_scale(right_x_vals)\n",
    "    \n",
    "        centroids = [[a,b] for a,b in zip(left_centers, right_centers)]        \n",
    "        return centroids\n",
    "\n",
    "    \n",
    "    def fit_lines(self, window_centroids, leftx, rightx, window_width, window_height):\n",
    "        \n",
    "        if len(leftx) == len(rightx):\n",
    "            vert_start = self.img_size[1] - window_height/2\n",
    "            vert_stop = window_height\n",
    "            y_values = np.linspace(vert_start, vert_stop, len(leftx), dtype = np.float32)\n",
    "\n",
    "        \n",
    "        # fit to a polynomial (ax^2 + bx + c)\n",
    "        left_fit = np.polyfit(y_values, leftx, 2)\n",
    "        left_fitx = left_fit[0] * (y_values**2) + left_fit[1] * y_values + left_fit[2]\n",
    "        left_fitx = np.array(left_fitx, np.int32)\n",
    "        \n",
    "        right_fit = np.polyfit(y_values, rightx, 2)\n",
    "        right_fitx = right_fit[0] * (y_values**2) + right_fit[1] * y_values + right_fit[2]\n",
    "        right_fitx = np.array(right_fitx, np.int32)\n",
    "        shift = 0\n",
    "        \n",
    "        left_lane = np.array(list(zip(np.concatenate((left_fitx - window_width/10 + shift, left_fitx[::-1] + window_width/10 + shift), axis = 0),\n",
    "                            np.concatenate((y_values, y_values[::-1]), axis = 0))), dtype = np.int32)\n",
    "        \n",
    "        right_lane = np.array(list(zip(np.concatenate((right_fitx - window_width/10 + shift, right_fitx[::-1] + window_width/10 + shift), axis = 0),\n",
    "                            np.concatenate((y_values, y_values[::-1]), axis = 0))), dtype = np.int32)\n",
    "\n",
    "        \n",
    "#         both_lanes = np.array(list(zip(left_fitx, right_fitx)), dtype = np.int32)\n",
    "#         print('lanes shape: ', both_lanes.shape)\n",
    "#         return both_lanes[0], both_lanes[1]\n",
    "        return left_lane, right_lane\n",
    "    \n",
    "    def draw_lines(self, left_lane, right_lane):\n",
    "        lanes = np.zeros((self.img_size[1], self.img_size[0], 3), dtype = np.uint8)\n",
    "        \n",
    "#         left_lane = left_lane.astype(np.uint8)\n",
    "#         right_lane = right_lane.astype(np.uint8)\n",
    "        \n",
    "#         # fill in the lane lines\n",
    "#         cv2.polylines()\n",
    "#         es \t( \tInputOutputArray  \timg,\n",
    "# \t\tInputArrayOfArrays  \tpts,\n",
    "# \t\tbool  \tisClosed,\n",
    "# \t\tconst Scalar &  \tcolor,\n",
    "# \t\tint  \tthickness = 1,\n",
    "# \t\tint  \tlineType = LINE_8,\n",
    "# \t\tint  \tshift = 0 \n",
    "        \n",
    "#         cv2.polylines(lanes, [left_lane], isClosed = False, thickness = 1, color = [255, 0, 0])\n",
    "#         cv2.polylines(lanes, [right_lane], isClosed = False, thickness = 1, color = [0, 255, 0])\n",
    "        \n",
    "        \n",
    "        cv2.fillPoly(lanes, [left_lane], color = [255, 0, 0])\n",
    "        cv2.fillPoly(lanes, [right_lane], color = [0,255, 0])\n",
    "        return lanes\n",
    "\n",
    "\n",
    "    def get_line_pts(self, mask, window_centroids):\n",
    "        \"\"\"\n",
    "        Here we find the points that will be used to draw the left and right windows\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        \n",
    "        # Points we will use for drawing on each level\n",
    "        left_points = np.zeros_like(mask)\n",
    "        right_points = np.zeros_like(left_points)\n",
    "        \n",
    "        left_x = []\n",
    "        right_x = []\n",
    "        \n",
    "        for level in range(0, len(window_centroids)):\n",
    "            # window_mask if a function to draw window boxes\n",
    "            left_x.append(window_centroids[level][0])\n",
    "            right_x.append(window_centroids[level][1])\n",
    "            \n",
    "            left_mask = draw_window_box(mask, self.window_width, self.window_height, \n",
    "                                        window_centroids[level][0],\n",
    "                                        level)\n",
    "            right_mask = draw_window_box(mask, self.window_width, self.window_height, \n",
    "                                        window_centroids[level][1],\n",
    "                                        level)\n",
    "            \n",
    "            left_points[(left_points == 255) | ((left_mask == 1))] = 255\n",
    "            right_points[(right_points == 255) | ((right_mask == 1))] = 255\n",
    "            \n",
    "        return [left_points, right_points], [left_x, right_x]\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def moving_average_scale(a):\n",
    "    mean = np.mean(a)\n",
    "    std = np.std(a)\n",
    "    standard = [((x - mean) / std)for x in a]\n",
    "    results = []\n",
    "    for x, y in zip(a, standard):\n",
    "        results.append(math.ceil(x - y))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_window_box(mask, window_width, window_height, window_centroid, level):\n",
    "    box = np.zeros_like(mask)\n",
    "    window_start_vertical = int(mask.shape[0] - (level + 1) * (window_height))\n",
    "    window_stop_vertical = int(mask.shape[0] - (level * window_height))\n",
    "\n",
    "    window_start_horizontal = max(0, int(window_centroid - window_width))\n",
    "    window_stop_horizontal = min(int(window_centroid + window_width), mask.shape[1])\n",
    "\n",
    "    box[window_start_vertical: window_stop_vertical, window_start_horizontal: window_stop_horizontal] = 1\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_lines_weighted( points, mask):\n",
    "        \"\"\"\n",
    "        Draw lines according to binary image mask weight\n",
    "        \"\"\"\n",
    "    \n",
    "        template = np.asarray(points[0] + points[1]).astype(np.uint8)\n",
    "        tmp = np.zeros((template.shape[0], template.shape[1], 3)).astype(np.uint8)\n",
    "        # make window red\n",
    "        \n",
    "        tmp[:,:,0] = np.zeros_like(template)\n",
    "        tmp[:,:,1] = template[:,:]\n",
    "        tmp[:,:,2] = tmp[:,:,0]\n",
    "        \n",
    "        combine_mask = np.array(cv2.merge((mask, mask, mask))).astype(np.uint8)\n",
    "        weighted = cv2.addWeighted(combine_mask, 1, tmp, 0.5, 0.0)\n",
    "        \n",
    "        return weighted, tmp, mask\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Lane Finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* For type uint8 LAB images the range is from (0, 255) for each channel\n",
    "* Isolate green stuff by looking at the l in LAB. L = lightness,\n",
    "* a: color opponents green-red\n",
    "* b: color opponents blue-yellow, yellow has positive values, blue has negative values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "laneFinder = LaneFinder(settings.ORIGINAL_SIZE, settings.UNWARPED_SIZE, camera_matrix, dist_coeffs, \n",
    "                        M, x_pixels_per_meter, y_pixels_per_meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = mpimg.imread(test_images[3])\n",
    "lanes = laneFinder.process_image(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(lanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "im = mpimg.imread(test_images[3])\n",
    "(road_lines, warped, unwarped_lines, weighted_warped, original_unweighted) = laneFinder.find_lane(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(road_lines)\n",
    "print('shape: ', road_lines.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(unwarped_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(weighted_warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(original_unweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LaneFinder():\n",
    "    def __init__(self, \n",
    "                 img_size, \n",
    "                 warped_size, \n",
    "                 camera_matrix, \n",
    "                 dist_coeffs,\n",
    "                 transform_matrix,\n",
    "                 x_pixels_per_meter, y_pixels_per_meter):\n",
    "        self.img_size = img_size\n",
    "        self.warped_size = warped_size\n",
    "        self.camera_matrix = camera_matrix\n",
    "        self.dist_coeffs = dist_coeffs\n",
    "        self.transform_matrix = transform_matrix\n",
    "        self.x_pixels_per_meter = x_pixels_per_meter\n",
    "        self.y_pixels_per_meter = y_pixels_per_meter\n",
    "        self.roi_mask = np.ones((self.warped_size[1], self.warped_size[0],3), dtype=np.uint8)\n",
    "        self.mask = np.zeros((self.warped_size[1], self.warped_size[0], 3), dtype = np.uint8)\n",
    "        self.real_mask = np.zeros((self.warped_size[1], self.warped_size[0],3), dtype = np.uint8)\n",
    "        self.left_line = LaneLineFinder(warped_size, x_pixels_per_meter, y_pixels_per_meter, kind = 'left')\n",
    "        self.right_line = LaneLineFinder(warped_size, self.x_pixels_per_meter, self.y_pixels_per_meter, kind = 'right') \n",
    "        self.found_both = False\n",
    "        \n",
    "        \n",
    "    def warp(self, img):\n",
    "        return cv2.warpPerspective(img, self.transform_matrix, self.warped_size, \n",
    "                                   flags=cv2.WARP_FILL_OUTLIERS + cv2.INTER_NEAREST)\n",
    "    \n",
    "    def unwarp(self, img):\n",
    "        return cv2.warpPerspective(img, self.transform_matrix, self.img_size, \n",
    "                                   flags = cv2.WARP_FILL_OUTLIERS + cv2.INTER_NEAREST + cv2.WARP_INVERSE_MAP)\n",
    "    \n",
    "    def undistort(self, img):\n",
    "        return cv2.undistort(img, self.camera_matrix, self.dist_coeffs)\n",
    "    \n",
    "    def add_weighted(self, base, lines):\n",
    "        return cv2.addWeighted(base, 1.0, lines, .6, 0.0)\n",
    "    \n",
    "    def process_image(self, image):\n",
    "        \"\"\"\n",
    "        Process image full pipeline applied to video stream\n",
    "        input: image: original image\n",
    "        output: original image with lane lines overlayed\n",
    "        \"\"\"\n",
    "        lanes = self.find_lane(image)\n",
    "        \n",
    "        # Unwarp the lane lines\n",
    "        unwarped_lanes = self.unwarp(lanes)\n",
    "        \n",
    "        # Overlay the warped lanes\n",
    "        \n",
    "        # option a) unwarp the image and then plot\n",
    "        # option b) overlay onto the actual image\n",
    "        weighted_warped = self.add_weighted(self.warp(image), lanes)\n",
    "        \n",
    "        drawn_lanes_original = self.add_weighted(image, unwarped_lanes)\n",
    "        \n",
    "        return drawn_lanes_original\n",
    "        \n",
    "        \n",
    "    \n",
    "    def find_lane(self, image, distorted = True, FLAG = False):\n",
    "        \"\"\"\n",
    "        Pipeline:\n",
    "        1) Undistort\n",
    "        2) Perspective Transform\n",
    "        3) Blur\n",
    "        4) Convert to HLS and LAB and use the Luminance channel to identify yellow lines\n",
    "        \"\"\"\n",
    "        if FLAG == True:\n",
    "            self.left_line.reset_lane_line()\n",
    "            self.right_line.reset_lane_lin()\n",
    "        \n",
    "        # 1) Undistort the image\n",
    "        # TODO: Add conditional to flag distortion\n",
    "        img = self.undistort(image)\n",
    "        \n",
    "        # 2) Apply perspective transform\n",
    "        warped = self.warp(img)\n",
    "        \n",
    "        # 3) Blur\n",
    "        blur_kernel = 5\n",
    "        img_hls = cv2.cvtColor(warped, cv2.COLOR_RGB2HLS)\n",
    "        img_lab = cv2.cvtColor(warped, cv2.COLOR_RGB2LAB)\n",
    "        \n",
    "        img_hls = cv2.medianBlur(img_hls, blur_kernel)\n",
    "        img_lab = cv2.medianBlur(img_lab, blur_kernel)\n",
    "        \n",
    "        # Get structuring element for morph transforms\n",
    "        # note: Select structuring element to be large enough so that it won't fit inside the objects to be removed\n",
    "        large_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (29, 29))\n",
    "        small_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
    "                \n",
    "        # The road is dark, so extract bright regions out of the image\n",
    "        # If L in HLS is greater than 190 then it is bright\n",
    "        # Also filter out low saturation < 50\n",
    "        hls_filter = cv2.inRange(img_hls, (0, 0, 50), (30, 192, 255))\n",
    "        \n",
    "        yellow = hls_filter & (img_lab[:,:,2].astype(np.uint8) > 127)\n",
    "            \n",
    "        # Logical not means find inverse because later on we will combine this mask with the self.mask\n",
    "        roi_mask = np.logical_not(yellow).astype(np.uint8)\n",
    "        # cut out the bright stuff\n",
    "        roi_mask = (roi_mask & (img_hls[:,:,1] < 245)).astype(np.uint8)\n",
    "        \n",
    "        # perform OPEN morphology (erosion + dilation) to reduce noise\n",
    "        roi_mask = cv2.morphologyEx(roi_mask, cv2.MORPH_OPEN, small_kernel)\n",
    "        \n",
    "        # roi_mask is a binary mask\n",
    "        # perform Dilation morphology for enhancement on larger features\n",
    "        roi_mask = cv2.dilate(roi_mask, large_kernel)\n",
    "\n",
    "\n",
    "        self.roi_mask[:,:,0] = (self.left_line.line_mask | self.right_line.line_mask) & roi_mask\n",
    "        self.roi_mask[:,:,1] = self.roi_mask[:,:,0]\n",
    "        self.roi_mask[:,:,2] = self.roi_mask[:,:,0]\n",
    "\n",
    "    \n",
    "        # perform tophat (original - opening)\n",
    "        tophat_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 3))\n",
    "        black = cv2.morphologyEx(img_lab[:,:,0], cv2.MORPH_TOPHAT, tophat_kernel)\n",
    "        lanes = cv2.morphologyEx(img_hls[:,:,1], cv2.MORPH_TOPHAT, tophat_kernel)\n",
    "        \n",
    "        rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 13))\n",
    "        yellow_lanes = cv2.morphologyEx(img_lab[:,:,2], cv2.MORPH_TOPHAT, rect_kernel)\n",
    "        \n",
    "        # Adaptive thresholding\n",
    "        self.mask[:,:,0] = cv2.adaptiveThreshold(black, 50, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 13, -6)\n",
    "        self.mask[:,:,1] = cv2.adaptiveThreshold(lanes, 60, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, -4)\n",
    "        self.mask[:,:,2] = cv2.adaptiveThreshold(yellow_lanes, 60, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, -1.5)\n",
    "\n",
    "        diff_mask = self.mask * self.roi_mask\n",
    "        small_ellipse = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 2))\n",
    "        \n",
    "        # grab any values that are nonzero\n",
    "        self.total_mask = np.any(diff_mask, axis = 2).astype(np.uint8)\n",
    "        # erosion on total_mask to reduce noise\n",
    "        self.total_mask = cv2.morphologyEx(self.total_mask, cv2.MORPH_ERODE, small_ellipse)\n",
    "        \n",
    "        left_mask = self.total_mask\n",
    "        right_mask = self.total_mask\n",
    "        if self.right_line.found:\n",
    "            # left mask is NOT the right line mask and not the right line's other mask, this mask is binary\n",
    "            left_mask = self.total_mask & np.logical_not(self.right_line.line_mask) & self.right_line.other_mask\n",
    "        if self.left_line.found:\n",
    "            right_mask = self.total_mask & np.logical_note(self.left_line.lin_mask) & self.left_line.other_mask\n",
    "            \n",
    "#         self.left_line.find_lane_line(left_mask, FLAG)\n",
    "#         self.right_line.find_lane_line(right_mask, FLAG)\n",
    "        \n",
    "        lane_lines = self.left_line.find_lane_line(left_mask, FLAG)\n",
    "        \n",
    "        return lane_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "laneFinder = LaneFinder(settings.ORIGINAL_SIZE, settings.UNWARPED_SIZE, camera_matrix, dist_coeffs, \n",
    "                        M, x_pixels_per_meter, y_pixels_per_meter)\n",
    "laneFinder = LaneFinder(settings.ORIGINAL_SIZE, settings.UNWARPED_SIZE, camera_matrix, dist_coeffs, \n",
    "                        M, x_pixels_per_meter, y_pixels_per_meter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "total_mask = laneFinder.find_lane(test_1)\n",
    "\n",
    "plt.imshow(total_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "laneFinder.draw_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "laneFinder.right_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Process image function that contains the entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [01:07<00:00, 18.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n",
      "CPU times: user 1min 19s, sys: 2.21 s, total: 1min 21s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "test_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "laneFinder = LaneFinder(settings.ORIGINAL_SIZE, settings.UNWARPED_SIZE, camera_matrix, dist_coeffs, \n",
    "                        M, x_pixels_per_meter, y_pixels_per_meter)\n",
    "white_clip = clip1.fl_image(laneFinder.process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(test_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Thresholding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    if orient == 'y':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "        \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    \n",
    "    scaled_sobel = np.uint8(255 * abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # grayscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # sobel x and y\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "\n",
    "    sobel_xy = np.sqrt(sobelx**2 + sobely**2)\n",
    "    print('sobel_xy: ', sobel_xy)\n",
    "    print(':: ',np.max(sobel_xy, axis = 0))\n",
    "    print('sobel_xy: ', sobel_xy.shape)\n",
    "    sf = np.max(sobel_xy/255)\n",
    "    gradmag = (sobel_xy/sf).astype(np.uint8)\n",
    "    \n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    abs_x= np.absolute(sobelx)\n",
    "    abs_y = np.absolute(sobely)\n",
    "    \n",
    "    \n",
    "    direction = np.arctan2(abs_y, abs_x)\n",
    "    \n",
    "    binary_output = np.zeros_like(direction)\n",
    "    binary_output[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def color_threshold(img, sthresh=(0, 255), vthresh = (0, 255)):\n",
    "    \"\"\"\n",
    "    This function takes in two thresholds, s in HLS and v in HSV and the image and it \n",
    "    returns the combination output binary of both gradients\n",
    "    \"\"\"\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    # 1) Convert to HLS color space\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    \n",
    "    # s channel\n",
    "    s = hls[:,:,2]\n",
    "    s_binary = np.zeros_like(s)\n",
    "    s_binary[(s > sthresh[0]) & (s <= sthresh[1])] = 1\n",
    "    \n",
    "    # v channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # isolate v channel\n",
    "    v = hsv[:,:,2]\n",
    "    v_binary = np.zeros_like(v)\n",
    "    v_binary[(v > vthresh[0]) & (v <= vthresh[1])] = 1\n",
    "\n",
    "    # create combination of both binaries as output\n",
    "    output_binary = np.zeros_like(s)\n",
    "    output_binary[(s_binary == 1) | (v_binary == 1)] = 255\n",
    "\n",
    "    return output_binary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
